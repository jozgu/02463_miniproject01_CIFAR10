{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = temp[0][0][0][:][:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "# imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Convolutional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     0] loss: 0.008\n",
      "[1,   300] loss: 2.301\n",
      "[1,   600] loss: 2.292\n",
      "[1,   900] loss: 2.262\n",
      "[1,  1200] loss: 2.175\n",
      "[1,  1500] loss: 2.090\n",
      "[2,     0] loss: 0.007\n",
      "[2,   300] loss: 2.005\n",
      "[2,   600] loss: 1.909\n",
      "[2,   900] loss: 1.839\n",
      "[2,  1200] loss: 1.793\n",
      "[2,  1500] loss: 1.736\n",
      "[3,     0] loss: 0.005\n",
      "[3,   300] loss: 1.672\n",
      "[3,   600] loss: 1.645\n",
      "[3,   900] loss: 1.616\n",
      "[3,  1200] loss: 1.580\n",
      "[3,  1500] loss: 1.590\n",
      "[4,     0] loss: 0.006\n",
      "[4,   300] loss: 1.533\n",
      "[4,   600] loss: 1.494\n",
      "[4,   900] loss: 1.504\n",
      "[4,  1200] loss: 1.465\n",
      "[4,  1500] loss: 1.474\n",
      "[5,     0] loss: 0.004\n",
      "[5,   300] loss: 1.413\n",
      "[5,   600] loss: 1.439\n",
      "[5,   900] loss: 1.392\n",
      "[5,  1200] loss: 1.389\n",
      "[5,  1500] loss: 1.391\n",
      "[6,     0] loss: 0.005\n",
      "[6,   300] loss: 1.334\n",
      "[6,   600] loss: 1.348\n",
      "[6,   900] loss: 1.331\n",
      "[6,  1200] loss: 1.294\n",
      "[6,  1500] loss: 1.304\n",
      "[7,     0] loss: 0.004\n",
      "[7,   300] loss: 1.270\n",
      "[7,   600] loss: 1.252\n",
      "[7,   900] loss: 1.251\n",
      "[7,  1200] loss: 1.246\n",
      "[7,  1500] loss: 1.258\n",
      "[8,     0] loss: 0.003\n",
      "[8,   300] loss: 1.203\n",
      "[8,   600] loss: 1.214\n",
      "[8,   900] loss: 1.192\n",
      "[8,  1200] loss: 1.175\n",
      "[8,  1500] loss: 1.198\n",
      "[9,     0] loss: 0.004\n",
      "[9,   300] loss: 1.145\n",
      "[9,   600] loss: 1.144\n",
      "[9,   900] loss: 1.137\n",
      "[9,  1200] loss: 1.145\n",
      "[9,  1500] loss: 1.143\n",
      "[10,     0] loss: 0.004\n",
      "[10,   300] loss: 1.089\n",
      "[10,   600] loss: 1.107\n",
      "[10,   900] loss: 1.103\n",
      "[10,  1200] loss: 1.114\n",
      "[10,  1500] loss: 1.078\n",
      "[11,     0] loss: 0.004\n",
      "[11,   300] loss: 1.055\n",
      "[11,   600] loss: 1.070\n",
      "[11,   900] loss: 1.048\n",
      "[11,  1200] loss: 1.072\n",
      "[11,  1500] loss: 1.058\n",
      "[12,     0] loss: 0.004\n",
      "[12,   300] loss: 1.027\n",
      "[12,   600] loss: 1.023\n",
      "[12,   900] loss: 1.040\n",
      "[12,  1200] loss: 1.006\n",
      "[12,  1500] loss: 1.019\n",
      "[13,     0] loss: 0.002\n",
      "[13,   300] loss: 1.003\n",
      "[13,   600] loss: 0.989\n",
      "[13,   900] loss: 0.965\n",
      "[13,  1200] loss: 0.981\n",
      "[13,  1500] loss: 0.978\n",
      "[14,     0] loss: 0.005\n",
      "[14,   300] loss: 0.943\n",
      "[14,   600] loss: 0.964\n",
      "[14,   900] loss: 0.950\n",
      "[14,  1200] loss: 0.969\n",
      "[14,  1500] loss: 0.960\n",
      "[15,     0] loss: 0.004\n",
      "[15,   300] loss: 0.921\n",
      "[15,   600] loss: 0.917\n",
      "[15,   900] loss: 0.920\n",
      "[15,  1200] loss: 0.923\n",
      "[15,  1500] loss: 0.933\n",
      "[16,     0] loss: 0.004\n",
      "[16,   300] loss: 0.902\n",
      "[16,   600] loss: 0.885\n",
      "[16,   900] loss: 0.898\n",
      "[16,  1200] loss: 0.908\n",
      "[16,  1500] loss: 0.896\n",
      "[17,     0] loss: 0.003\n",
      "[17,   300] loss: 0.862\n",
      "[17,   600] loss: 0.870\n",
      "[17,   900] loss: 0.879\n",
      "[17,  1200] loss: 0.867\n",
      "[17,  1500] loss: 0.886\n",
      "[18,     0] loss: 0.003\n",
      "[18,   300] loss: 0.826\n",
      "[18,   600] loss: 0.845\n",
      "[18,   900] loss: 0.866\n",
      "[18,  1200] loss: 0.845\n",
      "[18,  1500] loss: 0.852\n",
      "[19,     0] loss: 0.003\n",
      "[19,   300] loss: 0.824\n",
      "[19,   600] loss: 0.826\n",
      "[19,   900] loss: 0.835\n",
      "[19,  1200] loss: 0.823\n",
      "[19,  1500] loss: 0.830\n",
      "[20,     0] loss: 0.003\n",
      "[20,   300] loss: 0.800\n",
      "[20,   600] loss: 0.797\n",
      "[20,   900] loss: 0.796\n",
      "[20,  1200] loss: 0.809\n",
      "[20,  1500] loss: 0.816\n",
      "[21,     0] loss: 0.003\n",
      "[21,   300] loss: 0.764\n",
      "[21,   600] loss: 0.784\n",
      "[21,   900] loss: 0.788\n",
      "[21,  1200] loss: 0.781\n",
      "[21,  1500] loss: 0.790\n",
      "[22,     0] loss: 0.003\n",
      "[22,   300] loss: 0.747\n",
      "[22,   600] loss: 0.757\n",
      "[22,   900] loss: 0.779\n",
      "[22,  1200] loss: 0.753\n",
      "[22,  1500] loss: 0.766\n",
      "[23,     0] loss: 0.003\n",
      "[23,   300] loss: 0.717\n",
      "[23,   600] loss: 0.743\n",
      "[23,   900] loss: 0.741\n",
      "[23,  1200] loss: 0.758\n",
      "[23,  1500] loss: 0.762\n",
      "[24,     0] loss: 0.004\n",
      "[24,   300] loss: 0.701\n",
      "[24,   600] loss: 0.727\n",
      "[24,   900] loss: 0.735\n",
      "[24,  1200] loss: 0.719\n",
      "[24,  1500] loss: 0.735\n",
      "[25,     0] loss: 0.002\n",
      "[25,   300] loss: 0.682\n",
      "[25,   600] loss: 0.699\n",
      "[25,   900] loss: 0.732\n",
      "[25,  1200] loss: 0.699\n",
      "[25,  1500] loss: 0.711\n",
      "[26,     0] loss: 0.003\n",
      "[26,   300] loss: 0.652\n",
      "[26,   600] loss: 0.682\n",
      "[26,   900] loss: 0.692\n",
      "[26,  1200] loss: 0.716\n",
      "[26,  1500] loss: 0.701\n",
      "[27,     0] loss: 0.002\n",
      "[27,   300] loss: 0.655\n",
      "[27,   600] loss: 0.654\n",
      "[27,   900] loss: 0.697\n",
      "[27,  1200] loss: 0.673\n",
      "[27,  1500] loss: 0.694\n",
      "[28,     0] loss: 0.001\n",
      "[28,   300] loss: 0.630\n",
      "[28,   600] loss: 0.651\n",
      "[28,   900] loss: 0.655\n",
      "[28,  1200] loss: 0.658\n",
      "[28,  1500] loss: 0.682\n",
      "[29,     0] loss: 0.003\n",
      "[29,   300] loss: 0.615\n",
      "[29,   600] loss: 0.625\n",
      "[29,   900] loss: 0.636\n",
      "[29,  1200] loss: 0.664\n",
      "[29,  1500] loss: 0.644\n",
      "[30,     0] loss: 0.002\n",
      "[30,   300] loss: 0.592\n",
      "[30,   600] loss: 0.614\n",
      "[30,   900] loss: 0.617\n",
      "[30,  1200] loss: 0.626\n",
      "[30,  1500] loss: 0.635\n",
      "[31,     0] loss: 0.001\n",
      "[31,   300] loss: 0.577\n",
      "[31,   600] loss: 0.579\n",
      "[31,   900] loss: 0.586\n",
      "[31,  1200] loss: 0.635\n",
      "[31,  1500] loss: 0.647\n",
      "[32,     0] loss: 0.002\n",
      "[32,   300] loss: 0.565\n",
      "[32,   600] loss: 0.567\n",
      "[32,   900] loss: 0.608\n",
      "[32,  1200] loss: 0.595\n",
      "[32,  1500] loss: 0.615\n",
      "[33,     0] loss: 0.002\n",
      "[33,   300] loss: 0.539\n",
      "[33,   600] loss: 0.574\n",
      "[33,   900] loss: 0.564\n",
      "[33,  1200] loss: 0.589\n",
      "[33,  1500] loss: 0.609\n",
      "[34,     0] loss: 0.002\n",
      "[34,   300] loss: 0.536\n",
      "[34,   600] loss: 0.556\n",
      "[34,   900] loss: 0.553\n",
      "[34,  1200] loss: 0.585\n",
      "[34,  1500] loss: 0.583\n",
      "[35,     0] loss: 0.002\n",
      "[35,   300] loss: 0.532\n",
      "[35,   600] loss: 0.525\n",
      "[35,   900] loss: 0.550\n",
      "[35,  1200] loss: 0.556\n",
      "[35,  1500] loss: 0.561\n",
      "[36,     0] loss: 0.001\n",
      "[36,   300] loss: 0.510\n",
      "[36,   600] loss: 0.521\n",
      "[36,   900] loss: 0.532\n",
      "[36,  1200] loss: 0.548\n",
      "[36,  1500] loss: 0.573\n",
      "[37,     0] loss: 0.001\n",
      "[37,   300] loss: 0.498\n",
      "[37,   600] loss: 0.503\n",
      "[37,   900] loss: 0.516\n",
      "[37,  1200] loss: 0.531\n",
      "[37,  1500] loss: 0.570\n",
      "[38,     0] loss: 0.002\n",
      "[38,   300] loss: 0.471\n",
      "[38,   600] loss: 0.497\n",
      "[38,   900] loss: 0.510\n",
      "[38,  1200] loss: 0.512\n",
      "[38,  1500] loss: 0.528\n",
      "[39,     0] loss: 0.003\n",
      "[39,   300] loss: 0.468\n",
      "[39,   600] loss: 0.465\n",
      "[39,   900] loss: 0.501\n",
      "[39,  1200] loss: 0.521\n",
      "[39,  1500] loss: 0.532\n",
      "[40,     0] loss: 0.002\n",
      "[40,   300] loss: 0.455\n",
      "[40,   600] loss: 0.469\n",
      "[40,   900] loss: 0.475\n",
      "[40,  1200] loss: 0.496\n",
      "[40,  1500] loss: 0.505\n",
      "[41,     0] loss: 0.002\n",
      "[41,   300] loss: 0.439\n",
      "[41,   600] loss: 0.454\n",
      "[41,   900] loss: 0.461\n",
      "[41,  1200] loss: 0.496\n",
      "[41,  1500] loss: 0.484\n",
      "[42,     0] loss: 0.001\n",
      "[42,   300] loss: 0.421\n",
      "[42,   600] loss: 0.435\n",
      "[42,   900] loss: 0.465\n",
      "[42,  1200] loss: 0.466\n",
      "[42,  1500] loss: 0.487\n",
      "[43,     0] loss: 0.002\n",
      "[43,   300] loss: 0.395\n",
      "[43,   600] loss: 0.447\n",
      "[43,   900] loss: 0.453\n",
      "[43,  1200] loss: 0.462\n",
      "[43,  1500] loss: 0.474\n",
      "[44,     0] loss: 0.002\n",
      "[44,   300] loss: 0.413\n",
      "[44,   600] loss: 0.410\n",
      "[44,   900] loss: 0.426\n",
      "[44,  1200] loss: 0.450\n",
      "[44,  1500] loss: 0.455\n",
      "[45,     0] loss: 0.001\n",
      "[45,   300] loss: 0.389\n",
      "[45,   600] loss: 0.401\n",
      "[45,   900] loss: 0.425\n",
      "[45,  1200] loss: 0.436\n",
      "[45,  1500] loss: 0.459\n",
      "[46,     0] loss: 0.001\n",
      "[46,   300] loss: 0.372\n",
      "[46,   600] loss: 0.393\n",
      "[46,   900] loss: 0.410\n",
      "[46,  1200] loss: 0.418\n",
      "[46,  1500] loss: 0.449\n",
      "[47,     0] loss: 0.001\n",
      "[47,   300] loss: 0.351\n",
      "[47,   600] loss: 0.400\n",
      "[47,   900] loss: 0.388\n",
      "[47,  1200] loss: 0.414\n",
      "[47,  1500] loss: 0.430\n",
      "[48,     0] loss: 0.002\n",
      "[48,   300] loss: 0.347\n",
      "[48,   600] loss: 0.370\n",
      "[48,   900] loss: 0.391\n",
      "[48,  1200] loss: 0.400\n",
      "[48,  1500] loss: 0.434\n",
      "[49,     0] loss: 0.001\n",
      "[49,   300] loss: 0.336\n",
      "[49,   600] loss: 0.373\n",
      "[49,   900] loss: 0.365\n",
      "[49,  1200] loss: 0.383\n",
      "[49,  1500] loss: 0.406\n",
      "[50,     0] loss: 0.001\n",
      "[50,   300] loss: 0.333\n",
      "[50,   600] loss: 0.354\n",
      "[50,   900] loss: 0.375\n",
      "[50,  1200] loss: 0.392\n",
      "[50,  1500] loss: 0.398\n",
      "[51,     0] loss: 0.001\n",
      "[51,   300] loss: 0.327\n",
      "[51,   600] loss: 0.344\n",
      "[51,   900] loss: 0.362\n",
      "[51,  1200] loss: 0.385\n",
      "[51,  1500] loss: 0.384\n",
      "[52,     0] loss: 0.001\n",
      "[52,   300] loss: 0.311\n",
      "[52,   600] loss: 0.326\n",
      "[52,   900] loss: 0.347\n",
      "[52,  1200] loss: 0.361\n",
      "[52,  1500] loss: 0.392\n",
      "[53,     0] loss: 0.001\n",
      "[53,   300] loss: 0.301\n",
      "[53,   600] loss: 0.328\n",
      "[53,   900] loss: 0.326\n",
      "[53,  1200] loss: 0.360\n",
      "[53,  1500] loss: 0.377\n",
      "[54,     0] loss: 0.001\n",
      "[54,   300] loss: 0.288\n",
      "[54,   600] loss: 0.317\n",
      "[54,   900] loss: 0.341\n",
      "[54,  1200] loss: 0.343\n",
      "[54,  1500] loss: 0.370\n",
      "[55,     0] loss: 0.001\n",
      "[55,   300] loss: 0.277\n",
      "[55,   600] loss: 0.293\n",
      "[55,   900] loss: 0.334\n",
      "[55,  1200] loss: 0.338\n",
      "[55,  1500] loss: 0.368\n",
      "[56,     0] loss: 0.001\n",
      "[56,   300] loss: 0.291\n",
      "[56,   600] loss: 0.300\n",
      "[56,   900] loss: 0.340\n",
      "[56,  1200] loss: 0.350\n",
      "[56,  1500] loss: 0.372\n",
      "[57,     0] loss: 0.001\n",
      "[57,   300] loss: 0.273\n",
      "[57,   600] loss: 0.294\n",
      "[57,   900] loss: 0.309\n",
      "[57,  1200] loss: 0.342\n",
      "[57,  1500] loss: 0.334\n",
      "[58,     0] loss: 0.001\n",
      "[58,   300] loss: 0.267\n",
      "[58,   600] loss: 0.271\n",
      "[58,   900] loss: 0.303\n",
      "[58,  1200] loss: 0.315\n",
      "[58,  1500] loss: 0.327\n",
      "[59,     0] loss: 0.001\n",
      "[59,   300] loss: 0.248\n",
      "[59,   600] loss: 0.272\n",
      "[59,   900] loss: 0.294\n",
      "[59,  1200] loss: 0.315\n",
      "[59,  1500] loss: 0.322\n",
      "[60,     0] loss: 0.001\n",
      "[60,   300] loss: 0.250\n",
      "[60,   600] loss: 0.266\n",
      "[60,   900] loss: 0.283\n",
      "[60,  1200] loss: 0.309\n",
      "[60,  1500] loss: 0.327\n",
      "[61,     0] loss: 0.000\n",
      "[61,   300] loss: 0.236\n",
      "[61,   600] loss: 0.255\n",
      "[61,   900] loss: 0.288\n",
      "[61,  1200] loss: 0.303\n",
      "[61,  1500] loss: 0.326\n",
      "[62,     0] loss: 0.001\n",
      "[62,   300] loss: 0.242\n",
      "[62,   600] loss: 0.244\n",
      "[62,   900] loss: 0.273\n",
      "[62,  1200] loss: 0.295\n",
      "[62,  1500] loss: 0.294\n",
      "[63,     0] loss: 0.000\n",
      "[63,   300] loss: 0.224\n",
      "[63,   600] loss: 0.239\n",
      "[63,   900] loss: 0.270\n",
      "[63,  1200] loss: 0.298\n",
      "[63,  1500] loss: 0.298\n",
      "[64,     0] loss: 0.001\n",
      "[64,   300] loss: 0.220\n",
      "[64,   600] loss: 0.231\n",
      "[64,   900] loss: 0.284\n",
      "[64,  1200] loss: 0.280\n",
      "[64,  1500] loss: 0.299\n",
      "[65,     0] loss: 0.002\n",
      "[65,   300] loss: 0.220\n",
      "[65,   600] loss: 0.241\n",
      "[65,   900] loss: 0.251\n",
      "[65,  1200] loss: 0.257\n",
      "[65,  1500] loss: 0.308\n",
      "[66,     0] loss: 0.001\n",
      "[66,   300] loss: 0.227\n",
      "[66,   600] loss: 0.236\n",
      "[66,   900] loss: 0.258\n",
      "[66,  1200] loss: 0.265\n",
      "[66,  1500] loss: 0.279\n",
      "[67,     0] loss: 0.001\n",
      "[67,   300] loss: 0.209\n",
      "[67,   600] loss: 0.215\n",
      "[67,   900] loss: 0.245\n",
      "[67,  1200] loss: 0.285\n",
      "[67,  1500] loss: 0.277\n",
      "[68,     0] loss: 0.000\n",
      "[68,   300] loss: 0.206\n",
      "[68,   600] loss: 0.227\n",
      "[68,   900] loss: 0.224\n",
      "[68,  1200] loss: 0.245\n",
      "[68,  1500] loss: 0.268\n",
      "[69,     0] loss: 0.000\n",
      "[69,   300] loss: 0.193\n",
      "[69,   600] loss: 0.199\n",
      "[69,   900] loss: 0.243\n",
      "[69,  1200] loss: 0.258\n",
      "[69,  1500] loss: 0.273\n",
      "[70,     0] loss: 0.001\n",
      "[70,   300] loss: 0.190\n",
      "[70,   600] loss: 0.210\n",
      "[70,   900] loss: 0.217\n",
      "[70,  1200] loss: 0.239\n",
      "[70,  1500] loss: 0.231\n",
      "[71,     0] loss: 0.000\n",
      "[71,   300] loss: 0.171\n",
      "[71,   600] loss: 0.190\n",
      "[71,   900] loss: 0.222\n",
      "[71,  1200] loss: 0.231\n",
      "[71,  1500] loss: 0.290\n",
      "[72,     0] loss: 0.001\n",
      "[72,   300] loss: 0.216\n",
      "[72,   600] loss: 0.191\n",
      "[72,   900] loss: 0.227\n",
      "[72,  1200] loss: 0.244\n",
      "[72,  1500] loss: 0.269\n",
      "[73,     0] loss: 0.000\n",
      "[73,   300] loss: 0.179\n",
      "[73,   600] loss: 0.202\n",
      "[73,   900] loss: 0.215\n",
      "[73,  1200] loss: 0.234\n",
      "[73,  1500] loss: 0.281\n",
      "[74,     0] loss: 0.000\n",
      "[74,   300] loss: 0.180\n",
      "[74,   600] loss: 0.202\n",
      "[74,   900] loss: 0.211\n",
      "[74,  1200] loss: 0.226\n",
      "[74,  1500] loss: 0.237\n",
      "[75,     0] loss: 0.000\n",
      "[75,   300] loss: 0.166\n",
      "[75,   600] loss: 0.189\n",
      "[75,   900] loss: 0.191\n",
      "[75,  1200] loss: 0.205\n",
      "[75,  1500] loss: 0.236\n",
      "[76,     0] loss: 0.001\n",
      "[76,   300] loss: 0.164\n",
      "[76,   600] loss: 0.177\n",
      "[76,   900] loss: 0.188\n",
      "[76,  1200] loss: 0.218\n",
      "[76,  1500] loss: 0.226\n",
      "[77,     0] loss: 0.001\n",
      "[77,   300] loss: 0.172\n",
      "[77,   600] loss: 0.177\n",
      "[77,   900] loss: 0.193\n",
      "[77,  1200] loss: 0.219\n",
      "[77,  1500] loss: 0.243\n",
      "[78,     0] loss: 0.000\n",
      "[78,   300] loss: 0.160\n",
      "[78,   600] loss: 0.193\n",
      "[78,   900] loss: 0.199\n",
      "[78,  1200] loss: 0.218\n",
      "[78,  1500] loss: 0.256\n",
      "[79,     0] loss: 0.000\n",
      "[79,   300] loss: 0.159\n",
      "[79,   600] loss: 0.162\n",
      "[79,   900] loss: 0.192\n",
      "[79,  1200] loss: 0.211\n",
      "[79,  1500] loss: 0.230\n",
      "[80,     0] loss: 0.001\n",
      "[80,   300] loss: 0.188\n",
      "[80,   600] loss: 0.178\n",
      "[80,   900] loss: 0.182\n",
      "[80,  1200] loss: 0.208\n",
      "[80,  1500] loss: 0.221\n",
      "[81,     0] loss: 0.000\n",
      "[81,   300] loss: 0.142\n",
      "[81,   600] loss: 0.155\n",
      "[81,   900] loss: 0.180\n",
      "[81,  1200] loss: 0.214\n",
      "[81,  1500] loss: 0.207\n",
      "[82,     0] loss: 0.001\n",
      "[82,   300] loss: 0.155\n",
      "[82,   600] loss: 0.156\n",
      "[82,   900] loss: 0.179\n",
      "[82,  1200] loss: 0.195\n",
      "[82,  1500] loss: 0.227\n",
      "[83,     0] loss: 0.001\n",
      "[83,   300] loss: 0.140\n",
      "[83,   600] loss: 0.169\n",
      "[83,   900] loss: 0.200\n",
      "[83,  1200] loss: 0.206\n",
      "[83,  1500] loss: 0.218\n",
      "[84,     0] loss: 0.001\n",
      "[84,   300] loss: 0.172\n",
      "[84,   600] loss: 0.169\n",
      "[84,   900] loss: 0.195\n",
      "[84,  1200] loss: 0.187\n",
      "[84,  1500] loss: 0.236\n",
      "[85,     0] loss: 0.001\n",
      "[85,   300] loss: 0.153\n",
      "[85,   600] loss: 0.157\n",
      "[85,   900] loss: 0.187\n",
      "[85,  1200] loss: 0.218\n",
      "[85,  1500] loss: 0.235\n",
      "[86,     0] loss: 0.001\n",
      "[86,   300] loss: 0.165\n",
      "[86,   600] loss: 0.159\n",
      "[86,   900] loss: 0.164\n",
      "[86,  1200] loss: 0.189\n",
      "[86,  1500] loss: 0.183\n",
      "[87,     0] loss: 0.001\n",
      "[87,   300] loss: 0.140\n",
      "[87,   600] loss: 0.133\n",
      "[87,   900] loss: 0.156\n",
      "[87,  1200] loss: 0.187\n",
      "[87,  1500] loss: 0.189\n",
      "[88,     0] loss: 0.000\n",
      "[88,   300] loss: 0.132\n",
      "[88,   600] loss: 0.137\n",
      "[88,   900] loss: 0.166\n",
      "[88,  1200] loss: 0.173\n",
      "[88,  1500] loss: 0.193\n",
      "[89,     0] loss: 0.000\n",
      "[89,   300] loss: 0.117\n",
      "[89,   600] loss: 0.144\n",
      "[89,   900] loss: 0.155\n",
      "[89,  1200] loss: 0.176\n",
      "[89,  1500] loss: 0.208\n",
      "[90,     0] loss: 0.000\n",
      "[90,   300] loss: 0.120\n",
      "[90,   600] loss: 0.131\n",
      "[90,   900] loss: 0.153\n",
      "[90,  1200] loss: 0.212\n",
      "[90,  1500] loss: 0.218\n",
      "[91,     0] loss: 0.001\n",
      "[91,   300] loss: 0.154\n",
      "[91,   600] loss: 0.131\n",
      "[91,   900] loss: 0.182\n",
      "[91,  1200] loss: 0.166\n",
      "[91,  1500] loss: 0.171\n",
      "[92,     0] loss: 0.000\n",
      "[92,   300] loss: 0.121\n",
      "[92,   600] loss: 0.149\n",
      "[92,   900] loss: 0.145\n",
      "[92,  1200] loss: 0.160\n",
      "[92,  1500] loss: 0.165\n",
      "[93,     0] loss: 0.000\n",
      "[93,   300] loss: 0.130\n",
      "[93,   600] loss: 0.146\n",
      "[93,   900] loss: 0.187\n",
      "[93,  1200] loss: 0.218\n",
      "[93,  1500] loss: 0.214\n",
      "[94,     0] loss: 0.001\n",
      "[94,   300] loss: 0.137\n",
      "[94,   600] loss: 0.137\n",
      "[94,   900] loss: 0.163\n",
      "[94,  1200] loss: 0.165\n",
      "[94,  1500] loss: 0.210\n",
      "[95,     0] loss: 0.000\n",
      "[95,   300] loss: 0.136\n",
      "[95,   600] loss: 0.130\n",
      "[95,   900] loss: 0.140\n",
      "[95,  1200] loss: 0.138\n",
      "[95,  1500] loss: 0.171\n",
      "[96,     0] loss: 0.000\n",
      "[96,   300] loss: 0.129\n",
      "[96,   600] loss: 0.105\n",
      "[96,   900] loss: 0.148\n",
      "[96,  1200] loss: 0.159\n",
      "[96,  1500] loss: 0.176\n",
      "[97,     0] loss: 0.001\n",
      "[97,   300] loss: 0.118\n",
      "[97,   600] loss: 0.133\n",
      "[97,   900] loss: 0.178\n",
      "[97,  1200] loss: 0.156\n",
      "[97,  1500] loss: 0.172\n",
      "[98,     0] loss: 0.000\n",
      "[98,   300] loss: 0.130\n",
      "[98,   600] loss: 0.138\n",
      "[98,   900] loss: 0.135\n",
      "[98,  1200] loss: 0.172\n",
      "[98,  1500] loss: 0.183\n",
      "[99,     0] loss: 0.003\n",
      "[99,   300] loss: 0.142\n",
      "[99,   600] loss: 0.176\n",
      "[99,   900] loss: 0.149\n",
      "[99,  1200] loss: 0.151\n",
      "[99,  1500] loss: 0.222\n",
      "[100,     0] loss: 0.000\n",
      "[100,   300] loss: 0.111\n",
      "[100,   600] loss: 0.124\n",
      "[100,   900] loss: 0.139\n",
      "[100,  1200] loss: 0.149\n",
      "[100,  1500] loss: 0.165\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 300 == 0:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch+1}, {i:5d}] loss: {running_loss / 300:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory models_pytorch does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\otto\\OneDrive - Danmarks Tekniske Universitet\\DTU\\Kurser\\02463 Active machine learning and agency\\02463_miniproject01_CIFAR10\\CNN.ipynb Cell 14\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/otto/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/DTU/Kurser/02463%20Active%20machine%20learning%20and%20agency/02463_miniproject01_CIFAR10/CNN.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Save model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/otto/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/DTU/Kurser/02463%20Active%20machine%20learning%20and%20agency/02463_miniproject01_CIFAR10/CNN.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m PATH \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmodels_pytorch/cifar_net.pth\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/otto/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/DTU/Kurser/02463%20Active%20machine%20learning%20and%20agency/02463_miniproject01_CIFAR10/CNN.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m torch\u001b[39m.\u001b[39;49msave(net\u001b[39m.\u001b[39;49mstate_dict(), PATH)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\torch\\serialization.py:422\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    419\u001b[0m _check_dill_version(pickle_module)\n\u001b[0;32m    421\u001b[0m \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m--> 422\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    423\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[0;32m    424\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\torch\\serialization.py:309\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[1;34m(name_or_buffer)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    308\u001b[0m     container \u001b[39m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[1;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m container(name_or_buffer)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\torch\\serialization.py:287\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 287\u001b[0m     \u001b[39msuper\u001b[39m(_open_zipfile_writer_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49mPyTorchFileWriter(\u001b[39mstr\u001b[39;49m(name)))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Parent directory models_pytorch does not exist."
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 62 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    # for data in trainloader: # Test on the training set\n",
    "    for data in testloader: # Test on the test set (This is what we want to do)\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
